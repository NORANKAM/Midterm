{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiI6f8o3d3g-"
   },
   "source": [
    "# IADS midterm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please ensure all code is executed and the corresponding outputs are included. Write the code directly in this notebook rather than creating a new one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TTf_Bnvd3hC"
   },
   "source": [
    "## Part 1: Multiple choice and theoretic questions\n",
    "Please write your answer after each question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSjGjASjd3hD"
   },
   "source": [
    "### Question 1. What would the p-value of 0.04 mean for t-test comparing two samples of observations (select all that applies):\n",
    "A) sample averages are at least 4% different\n",
    "\n",
    "B) the samples follow the underlying distributions with the same mean\n",
    "\n",
    "C) the samples follow the underlying distributions with the different mean \n",
    "\n",
    "D) one can reject the null hypothesis that the samples follow the underlying distributions with the same mean at 5% significance level (or with 95% confidence) since p-values is below 0.05\n",
    "\n",
    "E) one can't reject the null hypothesis that the samples follow the underlying distributions with the same mean at 5% significance level (or 95% confidence) singe p-value does not reach 0.05\n",
    "\n",
    "F) one can reject the null hypothesis that the samples follows the underlying distributions with the different means at 5% significance level (or 95% confidence)\n",
    "\n",
    "G) probability that two samples have the same means is 4%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6unfyUk5d3hD"
   },
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9CqBtXTd3hE"
   },
   "source": [
    "### Question 2. What is true regarding normal and log-normal distributions:\n",
    "A) Quantities following log-normal distributions have higher probabilities for outliers compared to normal distributions\n",
    "\n",
    "B) Outliers significantly different from the mean are more common for the normally distributed variables compared to log normally distributed variables\n",
    "\n",
    "C) Logarithm of the normally distributed quantity follow a log-normal distribution\n",
    "\n",
    "D) Logarithm of the log-normally distributed quantity follows a normal distribution\n",
    "\n",
    "E) Probability density function of the log-normally distributed variable equals to the logarithm of the probability density function of the normally distributed variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyXKxxfbd3hE"
   },
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1e2LvTcd3hE"
   },
   "source": [
    "### Question 3. \n",
    "Imagine training a model which considers multiple sattelite images of urban traffic and tries to find groups of typical\n",
    "(repeated with minor deviations) scenarios. How would you classify this problem from Machine Learning perspective?\n",
    "\n",
    "A) Supervised leanring;\n",
    "\n",
    "B) Unsupervised learning;\n",
    "\n",
    "C) Semi-supervised learning;\n",
    "\n",
    "D) Reinforcement learning.\n",
    "\n",
    "Explain you choice:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHgxDzRCd3hF"
   },
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swhVyAV0d3hG"
   },
   "source": [
    "### Question 4. \n",
    "Please explain why would you need separate training, validation and test samples to learn the model. In which cases you may need all three, including a validation sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1aMU4d-Zd3hG"
   },
   "source": [
    "\n",
    "\n",
    "Answer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQn72oLf6K-F",
    "outputId": "fd179cb1-0eb3-4295-f06a-7c616e470282"
   },
   "outputs": [],
   "source": [
    "# !pip install rtree\n",
    "# !pip install pygeos\n",
    "# !pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89wuMoy9d3hH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import genextreme as gev\n",
    "from scipy.stats import pareto \n",
    "from scipy import stats\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9613wcxd3hI"
   },
   "source": [
    "## Part 2: NYPD data analysis\n",
    "\n",
    "In this part, you need to download New York Police Department (NYPD) complaints data for 2019 and write code for three following sections (each having own sub-sections): Data cleaning, Exploratory analysis and Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rWnrQw3d3hI"
   },
   "source": [
    "###  download NYPD complaints data:\n",
    "two options:\n",
    "1. download with curl or urllib methods\n",
    "2. download with API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YY6t1V2Zd3hI",
    "outputId": "7ef6e1c7-4ac0-4ab0-dd95-e806d7570203"
   },
   "outputs": [],
   "source": [
    "!curl https://data.cityofnewyork.us/api/views/qgea-i56i/rows.csv?accessType=DOWNLOAD > NYPD_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G5WMKgADd3hI"
   },
   "outputs": [],
   "source": [
    "# !wget https://data.cityofnewyork.us/api/views/qgea-i56i/rows.csv?accessType=DOWNLOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xlmVclo0d3hI"
   },
   "outputs": [],
   "source": [
    "# !wget https://www.dropbox.com/s/u78fk8g0wkf3xwu/NYPD_data.csv?dl=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSyThVTnd3hJ"
   },
   "source": [
    "Data dictionary: https://data.cityofnewyork.us/api/views/qgea-i56i/files/b21ec89f-4d7b-494e-b2e9-f69ae7f4c228?download=true&filename=NYPD_Complaint_Incident_Level_Data_Footnotes.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_eE0X2Wud3hJ"
   },
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543
    },
    "id": "Extgiapnd3hJ",
    "outputId": "2e063064-3e08-4980-ceff-22111258eb45"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('NYPD_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VXIIKok5d3hK",
    "outputId": "064236a0-4007-4f4c-d492-917adf4f44e0"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the shape of the data frame should be (8914838, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ygIHMvH-d3hK",
    "outputId": "3da25df0-fcb9-44b5-cabd-aab49adf4305"
   },
   "outputs": [],
   "source": [
    "data.OFNS_DESC.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q2T49scYd3hK",
    "outputId": "459a402b-f5e1-4407-de8a-fd3737ff2b71"
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWAH9C_Bd3hK"
   },
   "source": [
    "The complete data dictionary link is provided above. The focus of this notebook would be on columns - 'CMPLNT_NUM', 'CMPLNT_FR_DT', 'CMPLNT_FR_TM', 'OFNS_DESC', 'BORO_NM', 'PARKS_NM', 'Latitude', 'Longitude'.\n",
    "\n",
    "The 'CMPLNT_NUM' is a unique id for each complaint, 'CMPLNT_FR_DT' and 'CMPLNT_FR_TM' are date and time of complaint respectively, 'OFNS_DESC' is the type of offence reported, 'BORO_NM' is name of borough where complaint was reported, 'PARKS_NM' is name of park where complaint recorded (if any) and 'Latitude', 'Longitude' are location of complaint.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y9Ge_-RSd3hL"
   },
   "source": [
    "## Section 1 - Data cleaning tasks \n",
    "#### We have completed the majority of the data cleaning tasks, but there are still a few remaining items for you to address.(Marked as 'todo')\n",
    "1. Drop rows with a) missing/wrong complaint date and time b) missing borough name and c) duplicate complaint number ('CMPLNT_NUM' column)\n",
    "2. Filter out data where incident occured in a park or greenspace. Next, keep data for 2019 and after.\n",
    "3. Keep specific crime categories - type 1 crimes defined by FBI: The list is given here https://ucr.fbi.gov/crime-in-the-u.s/2011/crime-in-the-u.s.-2011/offense-definitions\n",
    "4. Filter by area (drop rows with location outside NYC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xt9hbVDdd3hL"
   },
   "source": [
    "### 1. filter out missing/wrong date and times, missing borough name and duplicate complaints from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SArfR4WFd3hL"
   },
   "outputs": [],
   "source": [
    "data['CMPLNT_FR_DT'] = pd.to_datetime(data['CMPLNT_FR_DT'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-O07XK9Rd3hL",
    "outputId": "997203de-2ba2-47d0-edae-404841f2036c"
   },
   "outputs": [],
   "source": [
    "data['CMPLNT_FR_TM'] = pd.to_datetime(data['CMPLNT_FR_TM'], format='%H:%M:%S', errors='coerce').dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gi29XJ1od3hL",
    "outputId": "2211f16a-11f2-499b-caa0-8a4005adc6bf"
   },
   "outputs": [],
   "source": [
    "print(data.CMPLNT_FR_DT.isna().sum())\n",
    "print(data.CMPLNT_FR_TM.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XFUgi8D4d3hL",
    "outputId": "86ac1017-1281-441b-8f5a-d05ff7cdd964"
   },
   "outputs": [],
   "source": [
    "data.dropna(subset=['CMPLNT_FR_DT', 'CMPLNT_FR_TM'], inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZtAOmrDYd3hM",
    "outputId": "feec4977-41f3-4205-e5ec-ebd335e4a16c"
   },
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['CMPLNT_NUM'], inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1XEw-z1d3hM",
    "outputId": "5b9b0a29-8715-4180-a8d5-3e85b44cae4f"
   },
   "outputs": [],
   "source": [
    "data.BORO_NM.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "129Rnu6Pd3hM",
    "outputId": "8ecbff06-9020-4951-ae39-25c7b71bf23f"
   },
   "outputs": [],
   "source": [
    "data = data[~data.BORO_NM.isna()]\n",
    "data = data[data.BORO_NM != '(null)']\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PYG0tuqbd3hM",
    "outputId": "392ff4b4-be49-4b56-d7c5-a9ad3cabded6"
   },
   "outputs": [],
   "source": [
    "data.BORO_NM.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEelr3B9d3hM"
   },
   "source": [
    "### 2. Remove rows where location is parks or greenspace and filter for 2019 and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZkK_zned3hM",
    "outputId": "f14bd122-1365-4d75-cb95-dc1675b5cb9b"
   },
   "outputs": [],
   "source": [
    "## check the timeline of data\n",
    "print(data.sort_values(by='CMPLNT_FR_DT', ascending=True).head(3)['CMPLNT_FR_DT'])\n",
    "print(data.sort_values(by='CMPLNT_FR_DT', ascending=False).head(3)['CMPLNT_FR_DT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4mrjCd8xd3hM",
    "outputId": "7a2c63e5-4b5a-481b-db69-ccb932fd7a5c"
   },
   "outputs": [],
   "source": [
    "# Todo: filter out the data before 2019-1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wuPGdplbd3hN",
    "outputId": "74b83e2d-07d1-4906-dc6e-dcb0dc810d94"
   },
   "outputs": [],
   "source": [
    "print(data.sort_values(by='CMPLNT_FR_DT', ascending=True).head(1)['CMPLNT_FR_DT'].values[0])\n",
    "print(data.sort_values(by='CMPLNT_FR_DT', ascending=False).head(1)['CMPLNT_FR_DT'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mzMfDL34d3hN",
    "outputId": "b398373c-2055-4509-df83-a50822db7b9e"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1gsTk7jNd3hN",
    "outputId": "52915080-ffa7-4f1f-9d94-dba95fd9d8ac"
   },
   "outputs": [],
   "source": [
    "data.PARKS_NM.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "569mOB8kd3hN",
    "outputId": "8108d529-6455-434e-9656-6614760d0931"
   },
   "outputs": [],
   "source": [
    "data = data[data.PARKS_NM == '(null)']\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint: We should have around 2.38M records after this step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UgeuIjvxd3hN"
   },
   "source": [
    "### 3. keep type 1 crimes as defined by FBI from the data : \n",
    "https://ucr.fbi.gov/crime-in-the-u.s/2011/crime-in-the-u.s.-2011/offense-definitions\n",
    "\n",
    "The crime type is present in the 'OFNS_DESC' column. You just need to keep the following categories: \"'ARSON', 'BURGLARY', 'FELONY ASSAULT', 'GRAND LARCENY' ,'GRAND LARCENY OF MOTOR VEHICLE',\n",
    "                'MURDER & NON-NEGL. MANSLAUGHTER', 'RAPE', 'ROBBERY'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8cS0Chg4d3hN",
    "outputId": "4135fdc7-dc34-47f5-9fe8-4e51dcbcf976"
   },
   "outputs": [],
   "source": [
    "data.OFNS_DESC.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fgfsVpQkd3hN",
    "outputId": "61f38e12-1e41-4f75-bc36-19ba1160879d"
   },
   "outputs": [],
   "source": [
    "data_type1 = data[data.OFNS_DESC.isin(['ARSON', 'BURGLARY', 'FELONY ASSAULT', 'GRAND LARCENY' ,'GRAND LARCENY OF MOTOR VEHICLE',\n",
    "                'MURDER & NON-NEGL. MANSLAUGHTER', 'RAPE', 'ROBBERY'])]\n",
    "data_type1.reset_index(drop=True, inplace=True)\n",
    "data_type1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "3Dnfk5tbd3hN",
    "outputId": "031e8645-e782-4748-ad67-85e46b79cde8"
   },
   "outputs": [],
   "source": [
    "data_type1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4iJ3w7RQd3hN"
   },
   "source": [
    "### 4. keep rows with location within NYC\n",
    "\n",
    "zip codes file is present in the github 'Data' repository as \"ZIPCODE.zip\". We also have already used it in homework 2.\n",
    "\n",
    "Do a spatial joint to keep only rows within NYC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "1Svlf4pxd3hN",
    "outputId": "92289e59-1b75-4ce6-f17f-281a88d0f837",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## zip codes map\n",
    "# zips = gpd.read_file('Data/ZIPCODE/ZIP_CODE_040114.shp')\n",
    "zips = gpd.read_file('ZIPCODE/ZIP_CODE_040114.shp')\n",
    "zips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWaBm-yWd3hO"
   },
   "source": [
    "Note: 'ZIPCODE' column has unique codes. The borough name is given in 'COUNTY' column. The counties and boroughs are synonymous in NYC. 'New York' county corresponds to Manhattan, 'Kings' to Brooklyn, 'Richmond' to Staten Island"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gi8tnzfUd3hO",
    "outputId": "0c3e3585-645a-4f74-de66-3d64795e9517"
   },
   "outputs": [],
   "source": [
    "zips.COUNTY.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "EVG5RPMSd3hO",
    "outputId": "d1c16e70-cc9b-49bc-e904-a6d110c7ed8b"
   },
   "outputs": [],
   "source": [
    "zips.plot(figsize=(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ju7ifAmtd3hO"
   },
   "outputs": [],
   "source": [
    "# Todo: filter out crime point beyond NYC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AsB5gkHqd3hO"
   },
   "outputs": [],
   "source": [
    "# YourDataframe.to_csv('NYC_crimes/crimes_NYC.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJ6tBB3Cd3hO"
   },
   "source": [
    "## Section 2 -Exploratory analysis tasks\n",
    "\n",
    "1. Visualize the time series of the total number of type 1 crimes for the whole city per day.\n",
    "2. Visualize part 1 crimes grouped on a) borough level as a bar plot and b) zip code level as a heatmap normalized by population (per 100,000). Use quantiles scheme colormap.\n",
    "3. Plot following bar plots: the total number of part 1 crimes by a) month, b) day of week( use weekday names for labels) and c) hour of day.\n",
    "4. Plot two bar plots: Day of the week and hour of the day timelines for felony vs grand larceny (normalized per 100,000 population, comparing these two types of crime on the same bar plots)\n",
    "5. Compare the %% decomposition of type 1 crimes by category of crime within different boroughs by plotting pie charts for each borough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fpz2V8dd3hO"
   },
   "source": [
    "### 1. time series plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: group total crimes by daily numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: plot as a time series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJNidjXtd3hO"
   },
   "source": [
    "### 2. plotting on borough and zip code level normalized by population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: group crime numbers by borough and normalize by their population (per 100,000). Population is given in the zips shapefile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: plot as a bar plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: now group by zip codes, normalize by their population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo:plot as a heatmap with quantiles color scheme\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9Bxm_Uwd3hP"
   },
   "source": [
    "### 3. bar plot of total crimes vs a) months b) day of week and c) hour of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Bar plots: Felony assault vs grand larceny grouped by a) day of week and b) hour of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: filter data for above crime types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: group the numbers and normalize by total city population (per 100,000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: plot two bar plots: one for day of week and other for hour of day\n",
    "# each plot should have comparison of the two type of crime numbers (normalized) by weekday and hour respectively\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tt_OtogAd3hR"
   },
   "source": [
    "## Section 3 - Hypothesis testing tasks\n",
    "\n",
    "1. Plot the distribution (density plot) of daily number of total type 1 crimes for 2019.\n",
    "Test the hypothesis if the distribution follows normal distribution.\n",
    "\n",
    "2. Plot the distributions (density plots) of daily number of total type 1 crimes for weekdays and weekends (normalized by population) and perform a) the t-test for the hypothesis that the average daily crime over weekdays and weekends is the same, b) the KS-test for the hypothesis that the weekday and weekend daily crime numbers follow the same distribution. Can you reject either hypothesis at the 10% significance level? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xd4j6UB4d3hS"
   },
   "outputs": [],
   "source": [
    "#introduce a custom function performing distribution analysis\n",
    "def distribution_analysis(x, log_scale = False, fit_distribution = 'None', bins = 50, vis_means = True, vis_curve = True, print_outputs = True):\n",
    "    #x - array of observations\n",
    "    #log_scale - analyze distribution of log(x) if True\n",
    "    #fit_distribution - fit the distribution ('normal', 'gev' or 'pareto') or do nothing if 'None'\n",
    "    #bins - how many bins to use for binning the data\n",
    "    #vis_means - show mean and std lines if True\n",
    "    #vis_curve - show interpolated distribution curve over the histogram bars if True\n",
    "    #print_outputs - print mean, std and percentiles\n",
    "    \n",
    "    if log_scale: \n",
    "        x1 = np.log10(x) #convert data to decimal logarithms\n",
    "        xlabel = 'log(values)' #reflect in x labels\n",
    "    else:\n",
    "        x1 = x #leave original scale \n",
    "        xlabel = 'values'\n",
    "    mu = x1.mean() #compute the mean\n",
    "    if log_scale: #if logscale, output all three - log mean, its original scale and original scale mean\n",
    "        print('Log mean = {:.2f}({:.2f}), mean = {:.2f}'.format(mu,10**mu,x.mean()))\n",
    "    else:\n",
    "        print('Mean = {:.2f}'.format(mu)) #otherwise print mean\n",
    "    sigma = x1.std() #compute and output standard deviation \n",
    "    print('Standard deviation = {:.2f}'.format(sigma))\n",
    "    for p in [1,5,25,50,75,95,99]: #output percentile values\n",
    "        print('{:d} percentile = {:.2f}'.format(p,np.percentile(x,p)))\n",
    "        \n",
    "    #visualize histogram and the interpolated line (if vis_curve=True) using seaborn\n",
    "    sns.distplot(x1, hist=True, kde=vis_curve, \n",
    "        bins=bins,color = 'darkblue', \n",
    "        hist_kws={'edgecolor':'black'},\n",
    "        kde_kws={'linewidth': 4})\n",
    "    \n",
    "    #show vertical lines for mean and std if vis_means = True\n",
    "    if vis_means:\n",
    "        plt.axvline(mu, color='r', ls='--', lw=2.0)\n",
    "        plt.axvline(mu-sigma, color='g', ls='--', lw=2.0)\n",
    "        plt.axvline(mu+sigma, color='g', ls='--', lw=2.0)\n",
    "        \n",
    "    ylim = plt.gca().get_ylim() #keep the y-range of original distribution density values \n",
    "    #(to make sure the fitted distribution would not affect it)\n",
    "    \n",
    "    h = np.arange(mu - 3 * sigma, mu + 3 * sigma, sigma / 100) #3-sigma visualization range for the fitted distribution\n",
    "    pars = None #fitted distribution parameters\n",
    "    \n",
    "    #fit and visualize the theoretic distribution\n",
    "    if fit_distribution == 'normal':\n",
    "        pars = norm.fit(x1)\n",
    "        plt.plot(h,norm.pdf(h,*pars),'r')\n",
    "    elif fit_distribution == 'gev':\n",
    "        pars = gev.fit(x1)\n",
    "        plt.plot(h,gev.pdf(h,*pars),'r')\n",
    "    elif fit_distribution == 'pareto':\n",
    "        pars = pareto.fit(x1)\n",
    "        plt.plot(h,pareto.pdf(h,*pars),'r')\n",
    "    \n",
    "    plt.xlabel(xlabel) #add x label \n",
    "    plt.ylim(ylim) #restore the y-range of original distribution density values \n",
    "    plt.show()\n",
    "    return pars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LhJzydBd3hS"
   },
   "source": [
    "### 1. plotting distributions and normality test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: group type 1 crime numbers per day for 2019\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: plot the distribution (density plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: normality test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lx9Zl8Fd3hS"
   },
   "source": [
    "### weekdays vs weekend distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eq88vxtMd3hT"
   },
   "outputs": [],
   "source": [
    "# Todo: create dataframes for weekdays and weekends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: group daily numbers for weekdays and weekends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: plot distribution (density plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: t-test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: k-s test\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
